{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: ARMA Processes and Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab session, we'll focus on simulating and estimating ARMA($p$, $q$) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we import all the necessary Python packages/libraries, and set up some configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from lib import *\n",
    "\n",
    "dpi = 120\n",
    "plt.rcParams['figure.dpi'] = dpi\n",
    "# _=plt.gcf().set_dpi(dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'data/'\n",
    "\n",
    "from statsmodels.tsa.api import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "\n",
    "import numpy.polynomial.polynomial as poly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define some function for estimation, calculation of ACF/PACF, and simulation of ARMA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ols(y, x, addcon=True):\n",
    "    \"\"\"Calculate OLS coefficients from scratch\"\"\"\n",
    "    Nobs = y.shape[0]\n",
    "    if addcon:\n",
    "        X = np.c_[np.ones((Nobs,1)), x] # append the [Nobs x 1] columns of ones.\n",
    "    else:\n",
    "        X = x\n",
    "    XX = np.dot(X.T, X) # X'X\n",
    "    Xy = np.dot(X.T, y) # X'y\n",
    "    beta_hat = np.linalg.solve(XX, Xy) # solve normal equations to calculate OLS estimates\n",
    "    resids = y - np.dot(X, beta_hat) # residual eps_hat = y - beta_hat*X \n",
    "    return beta_hat, resids, X\n",
    "\n",
    "\n",
    "### See: https://stackoverflow.com/questions/20701484/why-do-i-get-only-one-parameter-from-a-statsmodels-ols-fit\n",
    "def _sm_calc_ols(y, x, addcon=True):\n",
    "    \"\"\"Wrapper for statsmodels OLS regression\"\"\"\n",
    "    X = sm.add_constant(x) if addcon else x # add a constant if addcon==True\n",
    "    ols_results = sm.OLS(y,X).fit(cov_type='HC1')  # robust standard errors\n",
    "    beta_hat = ols_results.params # beta_hat\n",
    "    resids = ols_results.resid  # resids\n",
    "    return beta_hat, resids, X\n",
    "\n",
    "\n",
    "def lag_mat(y,nlags, fill_vals=np.nan):\n",
    "    \"\"\"Create a matrix of lags of a given vector\"\"\"\n",
    "    ### Source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.empty.html\n",
    "    y_lags = np.empty((y.shape[0], nlags+1)) \n",
    "    y_lags.fill(fill_vals)\n",
    "    \n",
    "    ### Include 0 lag\n",
    "    for lag in range(nlags + 1):\n",
    "        ### Source: https://docs.scipy.org/doc/numpy/reference/generated/numpy.roll.html\n",
    "        ### np.roll --> Elements that roll beyond the last position are re-introduced at the first.\n",
    "        y_lags[lag:, lag] = np.roll(y, shift=lag)[lag:] \n",
    "    return y_lags\n",
    "\n",
    "### Sample ACF and PACF for a given lag\n",
    "def calc_acf_lag_ols(y_lags, lag):\n",
    "    \"\"\"ACF for a given lag (OLS)\"\"\"\n",
    "    if lag==0: \n",
    "        return 1.\n",
    "    lhs = y_lags[lag:, 0]\n",
    "    rhs = y_lags[lag:, lag:lag+1]\n",
    "    beta_hat, _,_ = calc_ols(y=lhs, x=rhs, addcon=True)\n",
    "    return beta_hat[-1]\n",
    "\n",
    "def calc_pacf_lag_ols(y_lags, lag):\n",
    "    \"\"\"PACF for a given lag (OLS)\"\"\"\n",
    "    if lag==0: \n",
    "        return 1.\n",
    "    lhs = y_lags[lag:, 0]\n",
    "    ### need y_lags[lag:, 1:lag+1] instead of y_lags[lag:,lag:lag+1] (unlike \"calc_acf_lag_ols\")\n",
    "    rhs = y_lags[lag:, 1:lag+1] \n",
    "    beta_hat, _,_ = calc_ols(y=lhs, x=rhs, addcon=True)\n",
    "    return beta_hat[-1]\n",
    "\n",
    "### ACF and PACF for all lags\n",
    "def calc_acf_ols(y, nlags):\n",
    "    \"\"\"ACF for multiple lags\"\"\"\n",
    "    y_lags = lag_mat(y,nlags)\n",
    "    acf_list = [calc_acf_lag_ols(y_lags,lag) for lag in range(nlags + 1)]\n",
    "    return np.array(acf_list)\n",
    "\n",
    "def calc_pacf_ols(y, nlags):\n",
    "    \"\"\"PACF for multiple lags\"\"\"\n",
    "    y_lags = lag_mat(y,nlags)\n",
    "    pacf_list = [calc_pacf_lag_ols(y_lags,lag) for lag in range(nlags + 1)]\n",
    "    return np.array(pacf_list)\n",
    "\n",
    "### Plotting functions\n",
    "def my_plot_acf(y, nlags=10, ax=None, title_string='', \n",
    "                title_fontsize=None, xlabel_string='Time'):\n",
    "    \"\"\"Plotting ACF with approx SEs.\"\"\"\n",
    "    T = y.shape[0] \n",
    "    ### approx SEs: scaling used in asymptotic\n",
    "    se_approx = 1/np.sqrt(T)\n",
    "    ### set up figure\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "    ### ACF\n",
    "    ax.plot(calc_acf_ols(y, nlags), c='xkcd:true blue', \n",
    "            marker='o', markerfacecolor='xkcd:azure')\n",
    "    ax.fill_between(x=range(0,nlags+1), y1=-1.96*se_approx, y2=1.96*se_approx, facecolor='blue', alpha=0.1)\n",
    "    ax.set_xlabel(xlabel_string)\n",
    "    if title_fontsize!=None:\n",
    "        ax.set_title('${\\it ACF}$: ' + title_string, fontsize=title_fontsize)\n",
    "    else:\n",
    "        ax.set_title('${\\it ACF}$: ' + title_string)\n",
    "    \n",
    "def my_plot_pacf(y, nlags=10, ax=None, title_string='', \n",
    "                 title_fontsize=None, xlabel_string='Time'):\n",
    "    \"\"\"Plotting PACF with approx SEs.\"\"\"\n",
    "    T = y.shape[0]\n",
    "    # approx SEs: scaling used in aysmptotic\n",
    "    se_approx = 1/np.sqrt(T)\n",
    "    # set up figure\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5,5))\n",
    "    # PACF\n",
    "    ax.plot(calc_pacf_ols(y, nlags), c='xkcd:true blue', \n",
    "            marker='o', markerfacecolor='xkcd:azure')\n",
    "    ax.fill_between(x=range(0,nlags+1), y1=-1.96*se_approx, y2=1.96*se_approx, facecolor='blue', alpha=0.1)\n",
    "    ax.set_xlabel(xlabel_string)\n",
    "    if title_fontsize!=None:\n",
    "        ax.set_title('${\\it PACF}$: ' + title_string, fontsize=title_fontsize)\n",
    "    else:\n",
    "        ax.set_title('${\\it PACF}$: ' + title_string)\n",
    "\n",
    "def simulate_arma(ar=[], ma=[], nsample=100, burnin=0, paths=1, rnd=np.random.randn):\n",
    "    \"\"\"Simulate ARMA data\n",
    "       Assumption: White noise shocks are Gaussian.\n",
    "    \"\"\"\n",
    "    ### numpy arrays are reversed for easier indexing:\n",
    "    ar, ma = np.array(ar[::-1]), np.array(ma[::-1])\n",
    "    ### Orders (does not include zero lag)\n",
    "    p, q = len(ar), len(ma)\n",
    "    max_order = max(p,q)\n",
    "    \n",
    "    ### Total number of sample size\n",
    "    Nsim = nsample + burnin\n",
    "    ### \"Standard\" Guassian shocks: Normal(0,1)\n",
    "    eps = np.random.randn(paths, Nsim)\n",
    "    eps = rnd(paths, Nsim)\n",
    "\n",
    "    ### Initialize t < 0 with zeros\n",
    "    eps = np.concatenate((np.zeros((paths, max_order)), eps), axis=1)\n",
    "    y = np.zeros((paths, Nsim + max_order))\n",
    "    \n",
    "    ### Loop to construct the ARMA processes recursively.\n",
    "    for tt in range(max_order, Nsim + max_order):\n",
    "        y[:, tt] = np.sum(y[:, tt-p:tt]*ar, axis=1) + np.sum(eps[:,tt-q:tt]*ma, axis=1) + eps[:,tt]\n",
    "    \n",
    "    ### Drop initial zeros and burnin and transpose for plotting.\n",
    "    y = y[:, max_order + burnin:].T\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating ARMA models using `simulate_arma()`\n",
    "\n",
    "Below, we generate and AR(1) and a White-Noise with our \"own\" code of ARMA simulations from the above functions. Note we start at $y_0=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. White Noise \n",
    "y_wn = simulate_arma(nsample=100)\n",
    "\n",
    "### 2. AR(1) with persistence = 0.75\n",
    "phi1_model1 = 0.75\n",
    "y_ar1_model1 = simulate_arma(ar=[phi1_model1], nsample=250)\n",
    "\n",
    "fig1, axes1 = plt.subplots(nrows=2, ncols=1, figsize=(12,10))\n",
    "_=axes1[0].plot(y_wn)\n",
    "_=axes1[0].set_xlabel('Time', fontsize=16)\n",
    "_=axes1[0].set_title('White Noise', fontsize=18)\n",
    "_=axes1[0].axhline(y=0, linewidth=0.4)\n",
    "\n",
    "_=axes1[1].plot(y_ar1_model1)\n",
    "_=axes1[1].set_xlabel('Time', fontsize=16)\n",
    "_=axes1[1].set_title('AR($1$)' + ' with $\\phi$ = ' + str(phi1_model1) , fontsize=18)\n",
    "_=axes1[1].axhline(y=0, linewidth=0.4)\n",
    "\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating regression coefficients of AR(1) processes \n",
    "\n",
    "Let's simulate an AR(1) process (1000 iterations with 100 timesteps) and estimate the autoregressive coefficient using OLS. \n",
    "Is there evidence of bias in the coefficient estimates? \n",
    "Let's plot the empirical distribution of $\\sqrt{T}(\\hat{\\phi}-\\phi)$ based on our simulated estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # for density plot\n",
    "N=1000\n",
    "T=100\n",
    "betas = []\n",
    "phi1_model1 = 0.99\n",
    "for i in range(N):\n",
    "    y_ar1_model1 = simulate_arma(ar=[phi1_model1], nsample=T)\n",
    "    betas.append(calc_ols(y_ar1_model1[1:],y_ar1_model1[0:-1])[0][1][0])\n",
    "transformed_betas = np.sqrt(T)*(np.array(betas)-phi1_model1)\n",
    "        \n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "axes[0].hist(transformed_betas, bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Histogram')\n",
    "sns.kdeplot(data=transformed_betas, ax=axes[1], color='red', linewidth=2)\n",
    "axes[1].set_title('Density Plot')\n",
    "print(\"Mean:\", np.mean(betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Theoretical properties of ARMA($p$,$q$) models\n",
    "\n",
    "**Recall:** A stochastic process process $\\{x_t\\}$ is an ARMA($p$,$q$) process (autoregressive, moving average process of order $p$ and $q$, respectively) if we have\n",
    "\n",
    "$$\n",
    "x_t = \\mu + \\phi_1 x_{t-1} + \\phi_2 x_{t-2} + ... \\phi_p x_{t-p} + \\epsilon_{t} + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} +  ...  + \\theta_q \\epsilon_{t-q}\n",
    "$$\n",
    "\n",
    "where $\\epsilon_{t}$ is white noise, i.e. $E[\\epsilon_{t}]=0$ and $Var[\\epsilon_{t}]=\\sigma^2$, and without loss of generality, we set $\\mu$=0.\n",
    "\n",
    "If the coefficients $\\phi_i \\equiv 0$, then the ARMA($p$,$q$) process collapses to an MA($q$) process. \n",
    "\n",
    "Similarly, if $\\theta_i\\equiv 0$ then the ARMA($p$,$q$) process collapses to an AR($p$) process.\n",
    "\n",
    "A slightly more general formulation also used is given by the expression\n",
    "\n",
    "\n",
    "$$\n",
    "(x_t - \\phi_1 x_{t-1} - \\phi_2 x_{t-2} + ... \\phi_p x_{t-p})= \\epsilon_{t} + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} +  ...  + \\theta_q \\epsilon_{t-q}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Phi(L) x_t = \\Theta(L) \\epsilon_{t}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1-\\lambda_{\\phi,1} L) ...  (1-\\lambda_{\\phi,p} L) x_t = (1-\\lambda_{\\theta,1} L) ...  (1-\\lambda_{\\theta,p} L) \\epsilon_{t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now analyze the properties of ARMA models with the class `ArmaProcess` from the `statsmodel` package.\n",
    "\n",
    "Notation:\n",
    "- phi: AR coefficients\n",
    "- lambda_ar: factors in (1-lambda_ar_1 L)...(1-lambda_ar_p L)\n",
    "- r_phi=1/lambda_ar: roots of AR polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_process import ArmaProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arma_from_coeff(phi, theta):\n",
    "    if type(phi)==list:\n",
    "        phi = np.array(phi)\n",
    "    if type(theta)==list:\n",
    "        theta = np.array(theta)\n",
    "\n",
    "    phi_poly = np.r_[1, -phi]\n",
    "    theta_poly = np.r_[1, theta]\n",
    "\n",
    "    # arma_process = ArmaProcess([1], [1, -.7, .1])\n",
    "    arma_process = ArmaProcess(phi_poly, theta_poly)\n",
    "\n",
    "    _phi, _r_phi, _lam_phi = arma_process.arcoefs, arma_process.arroots, 1/arma_process.arroots\n",
    "    _theta, _r_theta, _lam_theta = arma_process.macoefs, arma_process.maroots, 1/arma_process.maroots\n",
    "\n",
    "    if len(_r_phi)==0:\n",
    "        _r_phi = np.array([np.inf])\n",
    "        _lam_phi = np.array([0])\n",
    "    if len(_r_theta)==0:\n",
    "        _r_theta = np.array([np.inf])\n",
    "        _lam_theta = np.array([0])\n",
    "        \n",
    "    print('\\nAR:\\t phi=', _phi, '\\tlambda_phi=',_lam_phi)\n",
    "    print('AR:\\t theta=', _theta, '\\tlambda_theta=',_lam_theta,'\\n')\n",
    "\n",
    "    return arma_process, _phi, _theta, _lam_phi, _lam_theta\n",
    "\n",
    "\n",
    "def arma_from_lambda(lam_phi, lam_theta):\n",
    "    if type(lam_phi)==list:\n",
    "        lam_phi = np.array(lam_phi)\n",
    "    if type(lam_theta)==list:\n",
    "        lam_theta = np.array(lam_theta)\n",
    "        \n",
    "    r_phi = 1/lam_phi\n",
    "    r_theta = 1/lam_theta    \n",
    "        \n",
    "    if len(r_phi)==0:\n",
    "        r_phi = np.array([np.inf])\n",
    "        lam_phi = np.array([0])\n",
    "    if len(r_theta)==0:\n",
    "        r_theta = np.array([np.inf])\n",
    "        lam_theta = np.array([0])\n",
    "\n",
    "    arma_process = ArmaProcess.from_roots(arroots=r_phi, maroots=r_theta)\n",
    "\n",
    "    _phi, _r_phi, _lam_phi = arma_process.arcoefs, arma_process.arroots, 1/arma_process.arroots\n",
    "    _theta, _r_theta, _lam_theta = arma_process.macoefs, arma_process.maroots, 1/arma_process.maroots\n",
    "\n",
    "    if len(_r_phi)==0:\n",
    "        _r_phi = np.array([np.inf])\n",
    "        _lam_phi = np.array([0])\n",
    "    if len(_r_theta)==0:\n",
    "        _r_theta = np.array([np.inf])\n",
    "        _lam_theta = np.array([0])\n",
    "\n",
    "    print('\\nAR:\\t phi=', _phi, '\\tlambda_phi=',_lam_phi)\n",
    "    print('AR:\\t theta=', _theta, '\\tlambda_theta=',_lam_theta,'\\n')\n",
    "\n",
    "    return arma_process, _phi, _theta, _lam_phi, _lam_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start with lambdas (1/roots)\n",
    "\n",
    "lam_phi = np.array([0.75,0.2])\n",
    "lam_theta = np.array([0.5, -0.2])\n",
    "\n",
    "arma_process, phi, theta, lam_phi, lam_theta = arma_from_lambda(lam_phi, lam_theta)\n",
    "\n",
    "_ = arma_from_coeff(phi, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start with phi and theta\n",
    "\n",
    "phi = np.array([0.95, -0.15])\n",
    "theta = np.array([-0.3, -0.1])\n",
    "\n",
    "arma_process, phi, theta, lam_phi, lam_theta = arma_from_coeff(phi, theta)\n",
    "\n",
    "_ = arma_from_lambda(lam_phi, lam_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AR(2)\n",
    "\n",
    "_lam_phi = np.array([0.75,0.2])\n",
    "_lam_theta = np.array([])\n",
    "\n",
    "arma_process, phi, theta, lam_phi, lam_theta = arma_from_lambda(_lam_phi, _lam_theta)\n",
    "\n",
    "print('Class: ',arma_process,'\\n')\n",
    "methods = dir(arma_process)\n",
    "methods = [x for x in methods if not '__' in x]\n",
    "print('Methods:', methods,'\\n')\n",
    "\n",
    "### useful methods of the ArmaProcess class\n",
    "arma_process.arcoefs\n",
    "arma_process.macoefs\n",
    "\n",
    "arma_process.arroots\n",
    "arma_process.maroots\n",
    "\n",
    "arma_process.isstationary\n",
    "\n",
    "print(arma_process.arpoly)\n",
    "print(arma_process.mapoly)\n",
    "\n",
    "arma_process.arma2ma(20)\n",
    "# _=plt.plot(arma_process.arma2ma(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.plot(arma_process.acf(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.plot(arma_process.impulse_response(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function: arma_analysis(arma_process, plot=True, H=20)\n",
    "### returns ACF, IRF \n",
    "\n",
    "def arma_analysis(arma_process, plot=True, H=20, plot_pacf=False):   \n",
    "    \n",
    "    print('-----------------------------')\n",
    "    print('ACF and IRF of ARMA processes')\n",
    "    print('-----------------------------\\n')\n",
    "\n",
    "    print('AR phi = \\t',arma_process.arcoefs)\n",
    "    print('MA theta = \\t',arma_process.macoefs,'\\n')\n",
    "\n",
    "    print('AR roots = \\t',arma_process.arroots)\n",
    "    print('AR lambdas = \\t',1/arma_process.arroots)\n",
    "    print('MA phi = \\t',arma_process.maroots)\n",
    "    print('MA lambdas = \\t',1/arma_process.maroots,'\\n')\n",
    "    \n",
    "    ### use methods of `ArmaProcess` object\n",
    "    ### ACF\n",
    "    acf = arma_process.acf(lags=H)\n",
    "    print('ACF:\\t',['{:.2f}'.format(i) for i in acf[:10]],'\\n')\n",
    "    if plot:\n",
    "        _=plt.figure()\n",
    "        _=plt.title('ACF')\n",
    "        _=plt.plot(acf, ls='-', marker='o', ms=4)\n",
    "\n",
    "        ### Comparison: ACF of AR(1) with phi=acf(1)\n",
    "        phi1 = arma_process.acf(lags=2)[1]\n",
    "        acf_ar1 = phi1**np.arange(0,H)\n",
    "        _=plt.plot(acf_ar1, ls='--', marker='o', ms=4)\n",
    "        plt.show()\n",
    "    \n",
    "    ### Impulse response function\n",
    "    ### Equivalent: MA representation\n",
    "\n",
    "    # print('IRF:\\n',['{:.2f}'.format(i) for i in arma_process.impulse_response(10)],'\\n')\n",
    "    # print(['{:.2f}'.format(i) for i in arma_process.arma2ma(lags=10)],'\\n')\n",
    "    irf = arma_process.impulse_response(H)\n",
    "    print('IRFF:\\t',['{:.2f}'.format(i) for i in irf[:10]],'\\n')\n",
    "\n",
    "    if plot:\n",
    "        _=plt.figure()\n",
    "        _=plt.title('IRF')\n",
    "        _=plt.plot(irf, marker='o', ms=4)\n",
    "\n",
    "        ### Comparison: ACF of AR(1) with phi=acf(1)\n",
    "        acf_ar1 = phi1**np.arange(0,H)\n",
    "        _=plt.plot(acf_ar1, ls='--', marker='o', ms=4)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        ### Compare ACF and IRF\n",
    "        _=plt.figure()\n",
    "        _=plt.title('ACF vs. IRF')\n",
    "        _=plt.plot(arma_process.impulse_response(H), marker='o', ms=4)\n",
    "        _=plt.plot(arma_process.acf(lags=H), ls='--', marker='o', ms=4)\n",
    "        plt.show()\n",
    "        \n",
    "    ### PACF\n",
    "    if plot_pacf:\n",
    "        pacf = arma_process.acf(lags=H)\n",
    "        print('PACF:\\t',['{:.2f}'.format(i) for i in pacf[:10]],'\\n')\n",
    "        if plot:\n",
    "            _=plt.figure()\n",
    "            _=plt.title('PACF')\n",
    "            _=plt.plot(acf, ls='-', marker='o', ms=4)\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "    return acf, irf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Use the function `arma_analysis()` to analyze the following models:\n",
    "\n",
    "1. ARMA(1,2)\n",
    "$$\n",
    "x_t =  0.5 x_{t-1} +  \\epsilon_{t} + 1.2 \\epsilon_{t-1} + -0.4 \\epsilon_{t-2} \n",
    "$$\n",
    "2. AR(2)\n",
    "$$\n",
    "x_t =  0.5 x_{t-1} + 0.4 x_{t-2} +  \\epsilon_{t}  \n",
    "$$\n",
    "3. AR(2)\n",
    "$$\n",
    "x_t =  0.5 x_{t-1} - 0.4 x_{t-2} +  \\epsilon_{t}  \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Compare the ACFs and IRFs of the following two processes:\n",
    "\n",
    "(a) an AR(1) process with $\\phi_1 = 0.5$\n",
    "\n",
    "(b) an ARMA(1,2) process with $\\phi_1 = 1.25$, $\\phi_2 = -0.375$, $\\theta_1 = -0.74$.\n",
    "\n",
    "Why are they so similar?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion: common zeroes\n",
    "\n",
    "What is particularly interesting about the ARMA($2$,$1$) process shown above? Let's write down the process using factored lag polynomials for both its AR and MA components:\n",
    "\n",
    "$$\n",
    "x_t = 1.25 x_{t-1} - 0.375 x_{t-2} + \\epsilon_{t} - 0.74 \\epsilon_{t-1}\n",
    "$$\n",
    "$$\n",
    "(1 - 1.25 L - 0.375 L^2)x_{t} = (1 -  0.74 L)\\epsilon_{t}\n",
    "$$\n",
    "$$\n",
    "(1 - 0.75 L)(1 - 0.5 L)x_{t} = (1 -  0.74 L)\\epsilon_{t}\n",
    "$$\n",
    "\n",
    "which gives us the AR roots $\\frac{1}{\\lambda_1} = 1.3333 $ and $\\frac{1}{\\lambda_2} = 2$. The (factored) MA lag polynomial $\\Theta(L)$ has the single root $\\frac{1}{\\zeta_1}\\approx 1.35$\n",
    "\n",
    "Thus the ARMA($2$,$1$) almost exhibits what we call a \"common factor\". That is,  $\\Phi(L)$ and $\\Theta(L)$ almost have a **common zero**. The AR factor $(1 - 0.75 L)$ is almost identical to the MA factor $(1 -  0.74 L)$, that is, they \"almost\" cancel each other out. \n",
    "\n",
    "Ifwe had $\\theta_1 = -0.75$ and the MA factor was $(1-0.75L)$, the process would have a common root of $4/3$ (outside the unit circle). Since the factor $(1-0.75L)$ cancels out, the process would be an **AR(1) process**. \n",
    "\n",
    "**Note:** In practice, for small $T$, it may be difficult to \"identify\" the data generating process. So we would never have an exactly common zero, and usually an approximately common zero. We may still want to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also see the similar properties by simulating from these two processes and comparing the mean of the OLS estimates for an AR(1) model\n",
    "\n",
    "phi1 = np.array([ 0.5])\n",
    "theta1 = np.array([])\n",
    "phi2 = np.array([1.25, -0.375])\n",
    "theta2 = np.array([-0.74])\n",
    "arma_process1, phi1, theta1, lam_phi1, lam_theta1 = arma_from_coeff(phi1, theta1)\n",
    "arma_process2, phi2, theta2, lam_phi2, lam_theta2 = arma_from_coeff(phi2, theta2)\n",
    "T, N = 100, 10000\n",
    "sim1 = arma_process1.generate_sample(nsample=(T,N))\n",
    "sim2 = arma_process2.generate_sample(nsample=(T,N))\n",
    "betas1 = []\n",
    "betas2 = []    \n",
    "for i in range(N):\n",
    "    y_ar1_model1 = sim1[:,i]\n",
    "    y_arma_model2 = sim2[:,i]\n",
    "    betas1.append(calc_ols(y_ar1_model1[1:],y_ar1_model1[0:-1])[0][1])\n",
    "    betas2.append(calc_ols(y_arma_model2[1:],y_arma_model2[0:-1])[0][1])\n",
    "print(\"Mean for AR(1):\", np.mean(betas1))\n",
    "print(\"Mean for ARMA(2,1):\", np.mean(betas2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial ACF vs. ACF\n",
    "\n",
    "ACF:\n",
    "$$\n",
    "x_{t} =  \\boldsymbol{\\rho_{j}}\\, x_{t-j} + e_{t}\n",
    "$$\n",
    "\n",
    "PACF: \n",
    "$$\n",
    "x_{t} =  \\phi_{1,j}\\, x_{t-1} + ...+ \\rho_{j-1,j}\\, x_{t-j+1}+ \\boldsymbol{\\rho_{j,j}}\\, x_{t-j} + e_{t}\n",
    "$$\n",
    "\n",
    "**Example:** AR(1) $x_{t} =  \\phi\\, x_{t-1} + e_{t}$\n",
    "\n",
    "ACF: $\\rho_j = \\phi^j$\n",
    "\n",
    "PACF: $\\rho_{1,1} = \\phi, \\quad \\rho_{2,2} = \\,?$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting the Partial Autocorrelation Function \n",
    "\n",
    "phi = [0.8]\n",
    "theta = []\n",
    "\n",
    "arma_process, phi, theta, lam_phi, lam_theta = arma_from_coeff(phi, theta)\n",
    "\n",
    "H = 20\n",
    "_=plt.plot(arma_process.acf(H), marker='o', ms=4)\n",
    "plt.show()\n",
    "\n",
    "_=plt.plot(arma_process.pacf(H), marker='o', ms=4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional exercises\n",
    "1. Compare ACF and PACF for AR(p) for different p\n",
    "2. Compute ACF and PACF for MA(q) for different q\n",
    "3. In practice, how could the shape of the ACF and PACF help you determine the lag orders?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating ARMA processes\n",
    "\n",
    "Options:\n",
    "1. Write your own routine, such as `simulate_arma()` above\n",
    "2. Use `statsmodels.tsa.arima_process.arma_generate_sample`\n",
    "3. Use the `generate_sample(nsample=(T,N))` method of the `ArmaProcess` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate the same ARMA(1,2) model 10 times\n",
    "phi = np.array([0.75])\n",
    "theta = np.array([1.2, -0.4])\n",
    "arma11, phi, theta, lam_phi, lam_theta = arma_from_coeff(phi, theta)\n",
    "\n",
    "T, N = 100, 10\n",
    "\n",
    "sim = arma11.generate_sample(nsample=(T,N))\n",
    "sim.shape\n",
    "\n",
    "_=plot_acf(sim[:,0])\n",
    "_=plot_acf(sim[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Generate simulations for 7 different ARMA models\n",
    "T = 5000  # simulation length\n",
    "N = 1     # number of samples\n",
    "np.random.seed(1234)\n",
    "\n",
    "## these are the inverse AR and MA roots\n",
    "lam_phi_list = [\n",
    "    [0.95], \n",
    "    [0.99], \n",
    "    [0.9999],\n",
    "    [0.5], \n",
    "    [0.5, 0.2],\n",
    "    [0.5, 0.45],\n",
    "    [0.9]\n",
    "    ]\n",
    "lam_theta_list = [\n",
    "    [0], \n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0],\n",
    "    [0.55],\n",
    "    [0]\n",
    "    ]\n",
    "\n",
    "ARMA_dict = {}\n",
    "phi_theta_df = pd.DataFrame()\n",
    "Samples_dict = {}\n",
    "Samples_df = pd.DataFrame()\n",
    "ARMA_acf_df = pd.DataFrame()\n",
    "for lam_phi, lam_theta, i in zip(lam_phi_list, lam_theta_list, range(1,len(lam_phi_list)+1)):\n",
    "    print('Case ', i)\n",
    "    print(lam_phi, lam_theta)\n",
    "    \n",
    "    l = arma_from_lambda(lam_phi, lam_theta)  # l is tuple with all return values\n",
    "    phi_theta_df[i] = [lam_phi, lam_theta, l[1].round(4), l[3].round(4)]\n",
    "    arma_pr = l[0]  # ArmaProcess\n",
    "    ARMA_dict[i] = arma_pr  # save model for later\n",
    "    \n",
    "    y = pd.DataFrame(arma_pr.generate_sample(nsample=(T,N)))\n",
    "    Samples_df[i] = y\n",
    "\n",
    "### adding a seasonality to AR(1) \n",
    "#Samples_df[7].iloc[::4] += 2\n",
    "Samples_df.iloc[::4, 6] += 2\n",
    "    \n",
    "#Samples_df.to_csv(path_data+'Lab2_ARMA_simulations.csv')\n",
    "Samples_df.to_pickle(path_data+'Lab2_ARMA_simulations.pickle')\n",
    "\n",
    "phi_theta_df.index = ['lam_phi', 'lam_theta', 'phi', 'theta']\n",
    "#phi_theta_df.to_csv(path_data+'Lab2_ARMA_simulations_true_phi_theta.csv')\n",
    "phi_theta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### theoretical ACF for each of the seven models\n",
    "\n",
    "ARMA_acf_df = pd.DataFrame()\n",
    "for i in ARMA_dict.keys():\n",
    "    arma_pr = ARMA_dict[i]\n",
    "    _acf = pd.DataFrame(arma_pr.acf(100))\n",
    "       \n",
    "    ARMA_acf_df = pd.concat([ARMA_acf_df, _acf], axis=1)\n",
    "    \n",
    "ARMA_acf_df.columns = ARMA_dict.keys()\n",
    "ARMA_acf_df.to_csv(path_data+'Lab2_ARMA_simulations_true_acf.csv')\n",
    "ARMA_acf_df.head()\n",
    "\n",
    "for i in ARMA_acf_df.columns:\n",
    "    _=plt.plot(ARMA_acf_df.loc[:30,i])\n",
    "_=plt.legend(ARMA_dict.keys())\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a `pickle` file with the simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samples_df = pd.read_pickle(path_data+'Lab2_ARMA_simulations.pickle')\n",
    "Samples_df.shape\n",
    "Samples_df.head()\n",
    "\n",
    "T = Samples_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the simulations\n",
    "fig, ax = plt.subplots(nrows=7, ncols=1, figsize=(12,16))\n",
    "\n",
    "for j in Samples_df.columns:\n",
    "    _=ax[j-1].plot(Samples_df.loc[:,j])\n",
    "    _=ax[j-1].set_xlabel('Time', fontsize=16)\n",
    "    _=ax[j-1].set_title('ARMA simulation, case ' + str(j), fontsize=18)\n",
    "    _=ax[j-1].axhline(y=0, linewidth=0.4)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will look at ACFs for different sample sizes\n",
    "\n",
    "T1 = [100, 200, 500, 1000, T]\n",
    "H = 100\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "acf_df = pd.DataFrame()\n",
    "pacf_df = pd.DataFrame()\n",
    "for i in Samples_df.columns:\n",
    "    _acf_df = pd.DataFrame()\n",
    "    _pacf_df = pd.DataFrame()\n",
    "    for t in T1:\n",
    "        y = Samples_df[i].loc[:t]\n",
    "        _acf_df[t] = acf(y, nlags=H)\n",
    "        _pacf_df[t] = pacf(y, nlags=10)\n",
    "    acf_df = pd.concat([acf_df, _acf_df], axis=1)\n",
    "    pacf_df = pd.concat([pacf_df, _pacf_df], axis=1)\n",
    "    \n",
    "acf_df.columns = pd.MultiIndex.from_product([Samples_df.columns, T1])\n",
    "pacf_df.columns = pd.MultiIndex.from_product([Samples_df.columns, T1])\n",
    "\n",
    "acf_df.head()\n",
    "pacf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's study cases 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's first look at the PACFs of the first three models\n",
    "# look only at PACF for sample size T=5000\n",
    "# What do we conclude?\n",
    "\n",
    "_=pacf_df.loc[:,idx[[1,2,3],T]].droplevel(1,axis=1).plot(marker='o', ms=3.5,title='PACF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now let's study the ACFs\n",
    "# Case 1\n",
    "# ACFs for different sample sizes\n",
    "i = 1\n",
    "cases_i = acf_df.loc[:,idx[[i]]]\n",
    "\n",
    "H = 75\n",
    "ylim = (-0.5, 1.1)\n",
    "\n",
    "_=plt.figure()\n",
    "for t in T1:\n",
    "    _=plt.plot(cases_i.loc[:,idx[:,t]].droplevel(1, axis=1).loc[:H])\n",
    "    _=plt.title('Case '+str(i))\n",
    "    _=plt.legend(T1)\n",
    "    _=plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Case 2\n",
    "i = 2\n",
    "cases_i = acf_df.loc[:,idx[[i]]]\n",
    "\n",
    "_=plt.figure()\n",
    "for t in T1:\n",
    "    _=plt.plot(cases_i.loc[:,idx[:,t]].droplevel(1, axis=1).loc[:H])\n",
    "    _=plt.title('Case '+str(i))\n",
    "    _=plt.legend(T1)\n",
    "    _=plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Case 3\n",
    "i = 3\n",
    "cases_i = acf_df.loc[:,idx[[i]]]\n",
    "\n",
    "_=plt.figure()\n",
    "for t in T1:\n",
    "    _=plt.plot(cases_i.loc[:,idx[:,t]].droplevel(1, axis=1).loc[:H])\n",
    "    _=plt.title('Case '+str(i))\n",
    "    _=plt.legend(T1)\n",
    "    _=plt.ylim(ylim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lesson**: Hard to draw firm conclusion from ACFs for small(ish) sample sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the 3 cases for a given sample size\n",
    "1. What do you learn?\n",
    "2. What sample size is necessary to differentiate the 3 processes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fix T and plot the ACFs of cases 1-3 in the same figure\n",
    "### What do you learn?\n",
    "### \n",
    "\n",
    "cases = acf_df.loc[:,idx[[1,2,3]]]\n",
    "H = 75\n",
    "\n",
    "for t in T1:\n",
    "    fig, ax = plt.subplots()\n",
    "    _p = cases.loc[:,idx[:,t]].droplevel(1, axis=1).loc[:H]\n",
    "    _=ax.plot(_p)\n",
    "    _=plt.title('T='+str(t)+', s.e.=$1/\\sqrt{T}$= '+str(round(1/t**.5,2)))\n",
    "    _=plt.legend(_p.columns)\n",
    "    _=plt.ylim(ylim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the estimated ACFs with the theoretically correct ACFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARMA_acf_df.head()\n",
    "H = 100\n",
    "for i in ARMA_acf_df.columns[:3]:\n",
    "    _=plt.plot(ARMA_acf_df.loc[:H,i])\n",
    "_=plt.legend(ARMA_dict.keys())\n",
    "_=plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 75\n",
    "for i in [1,2,3]:\n",
    "    _=plt.plot(ARMA_dict[i].acf(H), lw=3)\n",
    "    _=plt.plot(acf_df.loc[:H,idx[i]])\n",
    "    _=plt.title('Case '+str(i))\n",
    "    _=plt.legend(['true']+list(T1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_theta_df[[1,2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about cases 4-6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 20\n",
    "for i in [4,5,6]:\n",
    "    # _=plt.plot(ARMA_dict[i].acf(H), lw=4)\n",
    "    _=plt.plot(acf_df.loc[:H,idx[i,[100,200,500,T]]], lw=2)\n",
    "    _=plt.title('Case '+str(i))\n",
    "    _=plt.legend(T1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fix T and plot the ACFs in the same figure\n",
    "### What do we learn?\n",
    "\n",
    "cases = acf_df.loc[:,idx[[4,5,6]]]\n",
    "# H = 20\n",
    "\n",
    "for t in T1:\n",
    "    fig, ax = plt.subplots()\n",
    "    _p = cases.loc[:,idx[:,t]].droplevel(1, axis=1).loc[:H]\n",
    "    _=ax.plot(_p)\n",
    "    _=plt.title('T='+str(t)+', s.e.=$1/\\sqrt{T}$= '+str(round(1/t**.5,2)))\n",
    "    _=plt.legend(_p.columns)\n",
    "    _=plt.ylim(ylim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 15\n",
    "for i in [4,5,6]:\n",
    "    _=plt.plot(ARMA_dict[i].acf(H), lw=3)\n",
    "    _=plt.plot(acf_df.loc[:H,idx[i,[100,200,500,T]]])\n",
    "    _=plt.title('Case '+str(i))\n",
    "    _=plt.legend(['true']+list(T1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_theta_df[[4,5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, case 7 - seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=plt.plot(Samples_df.loc[1:100,7], marker='o', ms=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf7 = acf_df.loc[:,idx[[7]]].droplevel(0, axis=1)\n",
    "\n",
    "H = 50\n",
    "_=plt.plot(acf7[:H], marker='o', ms=3)\n",
    "_=plt.legend(T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samples_df[7][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Detect seasonality using regressions with seasonal dummies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Samples_df[7].iloc[:5000]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dict = {}\n",
    "for i in range(1,4):\n",
    "    dummies = np.zeros_like(y)\n",
    "    dummies[i::12] = 1\n",
    "    dummy_dict[i] = dummies\n",
    "dummies12 = pd.DataFrame(dummy_dict)\n",
    "dummies12.head()\n",
    "dummies12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lhs = y.iloc[1:]\n",
    "rhs = y.iloc[:-1]\n",
    "\n",
    "res = sm.regression.linear_model.OLS(lhs.values, sm.tools.tools.add_constant(rhs.values)).fit()\n",
    "print(res.summary())\n",
    "\n",
    "rhs = pd.concat([rhs,dummies12.iloc[:-1]], axis=1)\n",
    "res = sm.regression.linear_model.OLS(lhs.values, sm.tools.tools.add_constant(rhs.values)).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Why is the estimated AR coefficient so far below 0.9? How can we get closer to the \"truth\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application: Stock Dividends\n",
    "\n",
    "Let's analyze **monthly dividends** (in USD ($) nominal billions) from the CRSP-value weighted portfolio return index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp_div = pd.read_csv(path_data+'crspvw_dividends_1927-2022.csv', index_col='date', parse_dates=['date'])\n",
    "df_crsp_div = df_crsp_div.resample('ME').last()\n",
    "\n",
    "df_crsp_div.head()\n",
    "df_crsp_div.tail()\n",
    "\n",
    "print(df_crsp_div.reset_index().info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the time series of the monthly dividend cash flows from 1980 to the present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12,6))\n",
    "_=axes.plot(df_crsp_div['D'].loc['1980':])\n",
    "_=axes.set_xlabel('Months', fontsize=18)\n",
    "_=axes.set_ylabel('nominal dividends', fontsize=18)\n",
    "_=axes.set_title('Monthly Dividends: CRSP Value-Weighted Portfolio', fontsize=18)\n",
    "_=axes.axhline(y=0, linewidth=0.4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see **(1)** **EXPONENTIAL growth** and **(2)** **seasonalities**\n",
    "\n",
    "Let's address (1) by taking natural log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp_div['log_crsp_div'] = df_crsp_div['D'].apply(np.log)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "_=ax.plot(df_crsp_div.loc['1970':,'log_crsp_div'], lw=.5)\n",
    "_=ax.set_xlabel('Months', fontsize=18)\n",
    "_=ax.set_ylabel('log(nominal Dividends)', fontsize=18)\n",
    "_=ax.set_title('Monthly Dividends: CRSP Value-Weighted Portfolio', fontsize=18)\n",
    "# _=axe.axhline(y=0, linewidth=0.4)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_crsp_div.loc['2010':,'log_crsp_div'].head(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "y = df_crsp_div['log_crsp_div']\n",
    "decomposition = seasonal_decompose(y)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "seasonal['2020':]\n",
    "\n",
    "T1 = '2015'\n",
    "\n",
    "fig = plt.figure(figsize=(10,14))\n",
    "plt.subplot(411)\n",
    "plt.plot(y[T1:], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend[T1:], label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal[T1:],label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual[T1:], label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig = plt.figure(figsize=(10,14))\n",
    "plt.subplot(411)\n",
    "plt.plot(y[T1:], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend[T1:], label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal[T1:],label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual[T1:], label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the *ACF* and *PACF* for the log of CRSP dividends, $log(dividends_{1m})$, and the first difference of the log of CRSP dividends, $\\Delta log(dividends_{1m})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp_div['Dlog_crsp_div'] = df_crsp_div['log_crsp_div'] -\\\n",
    "                               df_crsp_div['log_crsp_div'].shift(1)\n",
    "df_crsp_div = df_crsp_div.dropna() # drop missings\n",
    "\n",
    "fig19, axes19 = plt.subplots(figsize=(12,6))\n",
    "_=axes19.plot(df_crsp_div.loc[',1990':,'Dlog_crsp_div'])\n",
    "_=axes19.set_xlabel('Months', fontsize=18)\n",
    "_=axes19.set_ylabel('$\\Delta$ log(nominal dividends)', fontsize=18)\n",
    "_=axes19.set_title('Monthly dividend growth', fontsize=18)\n",
    "_=axes19.axhline(y=0, linewidth=0.4)\n",
    "fig19.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACF/PCF for log dividends\n",
    "nlags=15\n",
    "fig20, axes20 = plt.subplots(nrows=1, ncols=2, figsize=(16,5))\n",
    "my_plot_acf(df_crsp_div['log_crsp_div'], nlags, \n",
    "            ax=axes20[0], title_string=\"$log(dividends_{1m,crsp})$\", \n",
    "            title_fontsize=18, xlabel_string=\"Months\")\n",
    "my_plot_pacf(df_crsp_div['log_crsp_div'], nlags, \n",
    "            ax=axes20[1], title_string=\"$log(dividends_{1m,crsp})$\", \n",
    "            title_fontsize=18, xlabel_string=\"Months\")\n",
    "fig20.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACF/PCF for dividend growth\n",
    "nlags=15\n",
    "fig21, axes21 = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "my_plot_acf(df_crsp_div['Dlog_crsp_div'], nlags, \n",
    "            ax=axes21[0], title_string=\"$\\Delta log(dividends_{1m,crsp})$\", \n",
    "            title_fontsize=18, xlabel_string=\"Months\")\n",
    "my_plot_pacf(df_crsp_div['Dlog_crsp_div'], nlags, \n",
    "            ax=axes21[1], title_string=\"$\\Delta log(dividends_{1m,crsp})$\", \n",
    "            title_fontsize=18, xlabel_string=\"Months\")\n",
    "\n",
    "fig21.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression of div growth on lag and dummies\n",
    "\n",
    "y = df_crsp_div['Dlog_crsp_div']\n",
    "\n",
    "lhs = y.iloc[1:]\n",
    "rhs = y.iloc[:-1]\n",
    "\n",
    "res = sm.regression.linear_model.OLS(lhs.values, sm.api.add_constant(rhs.values)).fit()\n",
    "print(res.summary())\n",
    "\n",
    "m = 1\n",
    "dummy_month = 1*(rhs.index.month==m)[:,None]\n",
    "for m in range(2,3):\n",
    "    dm = 1*(rhs.index.month==m)[:,None]\n",
    "    dummy_month = np.concatenate((dummy_month,dm), axis=1)\n",
    "dummy_month = pd.DataFrame(dummy_month)\n",
    "dummy_month.index = rhs.index\n",
    "\n",
    "rhs_dummies = pd.concat([rhs,dummy_month], axis=1)\n",
    "\n",
    "res = sm.regression.linear_model.OLS(lhs.values, sm.api.add_constant(rhs_dummies.values)).fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# y = df_crsp_div['log_crsp_div']\n",
    "decomposition = seasonal_decompose(y)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "trend.std(), seasonal.std(), residual.std()\n",
    "trend.std()/y.std(), seasonal.std()/y.std(), residual.std()/y.std()\n",
    "\n",
    "seasonal['2020':]\n",
    "\n",
    "T1 = '2015'\n",
    "\n",
    "fig = plt.figure(figsize=(10,14))\n",
    "plt.subplot(411)\n",
    "plt.plot(y[T1:], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend[T1:], label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal[T1:],label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual[T1:], label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_decompose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the seasonality in dividends by aggregating them over the last 12 months, using a rolling sum\n",
    "\n",
    "$$\n",
    "D^{12}_t = \\sum_{i=0}^{11} D_{t-i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp_div['D12'] = df_crsp_div['D'].rolling(12).sum()\n",
    "df_crsp_div = df_crsp_div.dropna() # drop missings\n",
    "#print(df_crsp_div.head())\n",
    "#print(df_crsp_div.tail())\n",
    "\n",
    "fig22, axes22 = plt.subplots(figsize=(12,6))\n",
    "_=axes22.plot(df_crsp_div['D12'])\n",
    "_=axes22.set_xlabel('Months', fontsize=18)\n",
    "_=axes22.set_ylabel('nominal dividends', fontsize=18)\n",
    "_=axes22.set_title('Trailing 12-Month Dividends: CRSP Value-Weighted Portfolio', fontsize=18)\n",
    "_=axes22.axhline(y=0, linewidth=0.4)\n",
    "fig22.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we only see **EXPONENTIAL growth**. Let's take logs and first differences of the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crsp_div['log_D12'] = df_crsp_div['D12'].apply(np.log)\n",
    "df_crsp_div = df_crsp_div.dropna() # drop missings\n",
    "#print(df_crsp_div.head())\n",
    "#print(df_crsp_div.tail())\n",
    "\n",
    "fig23, axes23 = plt.subplots(figsize=(12,6))\n",
    "_=_=axes23.plot(df_crsp_div['log_D12'])\n",
    "_=_=axes23.set_xlabel('Months', fontsize=18)\n",
    "_=_=axes23.set_ylabel('log(nominal dividends)', fontsize=18)\n",
    "_=_=axes23.set_title('Trailing 12-Month Log Dividends: CRSP Value-Weighted Portfolio', fontsize=18)\n",
    "# _=axes23.axhline(y=0, linewidth=0.4)\n",
    "fig23.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get **LINEAR growth**. The seasonality is gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_crsp_div['Dlog_D12'] = df_crsp_div['log_D12'] - df_crsp_div['log_D12'].shift(1) # monthly growth in cumulative dividends\n",
    "df_crsp_div['Dlog_D12'] = df_crsp_div['log_crsp_div'] - df_crsp_div['log_crsp_div'].shift(12) # year-over-year growth\n",
    "df_crsp_div = df_crsp_div.dropna() # drop missings\n",
    "#print(df_crsp_div.head())\n",
    "#print(df_crsp_div.tail())\n",
    "\n",
    "fig24, axes24 = plt.subplots(figsize=(12,6))\n",
    "_=_=axes24.plot(df_crsp_div['Dlog_D12'])\n",
    "_=_=axes24.set_xlabel('Months', fontsize=18)\n",
    "_=_=axes24.set_ylabel('$\\Delta$ log(nominal dividends)', fontsize=18)\n",
    "_=_=axes24.set_title('Trailing 12-Month Dividend Growth: CRSP Value-Weighted Portfolio', fontsize=18)\n",
    "_=_=axes24.axhline(y=0, linewidth=0.4)\n",
    "fig24.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Success!** It seems like we have a stationary process, with neither trend nor seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute the *ACF* and *PACF* for the log of our 12-month CRSP dividends, $log(dividends_{12m})$, and the new dividend growth series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACF/PCF for log 12m-trailing dividends\n",
    "nlags=15\n",
    "fig25, axes25 = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "my_plot_acf(df_crsp_div['log_D12'], nlags, \n",
    "            ax=axes25[0], title_string=\"$log(dividends_{12m})$\", \n",
    "            title_fontsize=18, xlabel_string=\"Months\")\n",
    "my_plot_pacf(df_crsp_div['log_D12'], nlags, \n",
    "            ax=axes25[1], title_string=\"$log(dividends_{12m})$\", \n",
    "             title_fontsize=18, xlabel_string=\"Months\")\n",
    "fig25.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ACF/PCF for 12-month dividend growth\n",
    "nlags=15\n",
    "fig26, axes26 = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "my_plot_acf(df_crsp_div['Dlog_D12'], nlags, \n",
    "            ax=axes26[0], title_string=\"$\\Delta log(dividends_{12m})$\", \n",
    "            title_fontsize=18, xlabel_string=\"Months\")\n",
    "my_plot_pacf(df_crsp_div['Dlog_D12'], nlags, \n",
    "            ax=axes26[1], title_string=\"$\\Delta  log(dividends_{12m})$\", \n",
    "             title_fontsize=18, xlabel_string=\"Months\")\n",
    "fig26.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What ARMA($p$,$q$) processes do both $log(dividends_{12m})$ and $\\Delta log(dividends_{12m})$ follow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "y = df_crsp_div['Dlog_D12']\n",
    "decomposition = seasonal_decompose(y)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "trend.std(), seasonal.std(), residual.std()\n",
    "trend.std()/y.std(), seasonal.std()/y.std(), residual.std()/y.std()\n",
    "\n",
    "seasonal['2020':]\n",
    "\n",
    "T1 = '2015'\n",
    "\n",
    "fig = plt.figure(figsize=(10,14))\n",
    "plt.subplot(411)\n",
    "plt.plot(y[T1:], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend[T1:], label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal[T1:],label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual[T1:], label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Changing the frequency\n",
    "\n",
    "An alternative to 12-month trailing sums is to use *annual* observations of dividends, e.g., dividends in December of every year.  Repeat the analysis with annual dividend observations and compare the results to those we got with MA(12)-dividends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: What have we learned?\n",
    "\n",
    "1. Dividends are highly seasonal\n",
    "2. Removing seasonality is difficult\n",
    "3. Some ways to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Parsimonious MA($1$) model\n",
    "\n",
    "Let's simulate the following MA($1$) model:\n",
    "$$\n",
    "y_t = \\varepsilon_t - \\varepsilon_{t-1} \n",
    "$$\n",
    "\n",
    "What is a particuarly parsimonious way in which we can transform this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simulate\n",
    "np.random.seed(5)\n",
    "ysim = simulate_arma(ma=[-1], nsample=500).squeeze()\n",
    "\n",
    "### Note that differencing doesn't help\n",
    "fig27, axes27 = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "for d in range(2):\n",
    "    if d==0:\n",
    "        Dysim = np.copy(ysim)\n",
    "        axes27[d,0].plot(Dysim)\n",
    "    else:\n",
    "        Dysim = Dysim[1:] - Dysim[:-1]\n",
    "        axes27[d,0].plot(Dysim[:200])\n",
    "    axes27[d,0].set_title('Diff = %d'% d, fontsize=18)\n",
    "    ### ACF/PACF\n",
    "    my_plot_acf(y=Dysim, nlags=10 , ax=axes27[d,1], title_fontsize=18)\n",
    "    my_plot_pacf(y=Dysim, nlags=10 , ax=axes27[d,2], title_fontsize=18)\n",
    "    \n",
    "fig27.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By cumulating the $y_t$ process over time, we can get a much more parsimonious representation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's instead consider the cumulative sum: {sum from 0 to t}y_t = e_t\n",
    "y_cumsum = np.cumsum(ysim) #https://docs.scipy.org/doc/numpy/reference/generated/numpy.cumsum.html\n",
    "\n",
    "fig28, axes28 = plt.subplots(nrows=1, ncols=3, figsize=(15,5))\n",
    "axes28[0].plot(y_cumsum)\n",
    "axes28[0].set_xlabel('Time', fontsize=16)\n",
    "axes28[0].set_title(\"Cumulative Sum of $\\{y_t\\}_{t\\geq0}$\", fontsize=18)\n",
    "\n",
    "### ACF/PACF\n",
    "my_plot_acf(y=y_cumsum, nlags=10 , ax=axes28[1], title_fontsize=18)\n",
    "my_plot_pacf(y=y_cumsum, nlags=10 , ax=axes28[2], title_fontsize=18)\n",
    "\n",
    "fig28.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
